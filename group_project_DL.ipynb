{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shujuan12/Data_management_group10/blob/main/group_project_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "60e8e917ea5b4762b1cc8a489aa30eb6",
        "deepnote_cell_type": "markdown",
        "tags": [],
        "id": "DTuW7pGNZ6yA"
      },
      "source": [
        "# Home assignment\n",
        "\n",
        "* Author: Romain Tavenard (@rtavenar)\n",
        "* License: CC-BY-NC-SA\n",
        "\n",
        "A home assignment from a course on Deep Learning at EDHEC.\n",
        "\n",
        "## Problem statement\n",
        "\n",
        "The dataset we are interested in here is called \"CIFAR10\". It is described [in this page](https://keras.io/api/datasets/cifar10/).\n",
        "\n",
        "You should load the data, **select only 5,000 samples out of the total 50,000 ones**, and preprocess it if needed.\n",
        "You should compare several candidate neural network architectures, and make a decision about which is best for the task at hand.\n",
        "You should be explicit about the indicator(s) you base your decision on.\n",
        "\n",
        "Finally, as a bonus, you could try to evaluate whether it is better to:\n",
        "* train a model from scratch on this dataset alone ;\n",
        "* use a large model that was pre-trained on ImageNet ;\n",
        "* pre-train a model on another dataset called [CIFAR100](https://keras.io/api/datasets/cifar100/) and fine-tune it on CIFAR10.\n",
        "\n",
        "## Deadline\n",
        "\n",
        "Deadline for this home assignment is February 28th, 2025.\n",
        "You should use the link on moodle to hand in your assignment.\n",
        "A single ipynb file should be provided,\n",
        "with execution traces.\n",
        "This assignment is to be done **by groups of three, at most** and names of all students should be included in the file name.\n",
        "\n",
        "## Data loading\n",
        "\n",
        "You can use the dedicated `keras` utility to load this dataset: <https://keras.io/api/datasets/cifar10/>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. 固定随机种子，保证结果一致\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# 2. 加载 CIFAR-10 数据\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# 3. 从 50,000 张图片中**随机选择 5,000 张**\n",
        "sample_indices = np.random.choice(x_train.shape[0], 5000, replace=False)  # 不放回抽样\n",
        "x_sampled = x_train[sample_indices]\n",
        "y_sampled = y_train[sample_indices]\n",
        "\n",
        "# 3. 归一化（像素值 0-255 -> 0-1）\n",
        "x_sampled = x_sampled.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# 4. 划分训练集和测试集（80% 训练，20% 测试）\n",
        "x_train_sub, x_val_sub, y_train_sub, y_val_sub = train_test_split(\n",
        "    x_sampled, y_sampled, test_size=0.2, random_state=seed\n",
        ")\n",
        "\n",
        "# 5. 将标签转换为 one-hot 编码（适用于 Softmax 分类）\n",
        "y_train_sub = keras.utils.to_categorical(y_train_sub, 10)\n",
        "y_val_sub = keras.utils.to_categorical(y_val_sub, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# 输出数据形状，确保正确\n",
        "print(\"训练集:\", x_train_sub.shape, y_train_sub.shape)\n",
        "print(\"验证集:\", x_val_sub.shape, y_val_sub.shape)\n",
        "print(\"测试集:\", x_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4FNZ5hhfhDr",
        "outputId": "e7c1cc52-01c4-49c8-95cf-8979507ed3df"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "训练集: (4000, 32, 32, 3) (4000, 10)\n",
            "验证集: (1000, 32, 32, 3) (1000, 10)\n",
            "测试集: (10000, 32, 32, 3) (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.Training Strategy-train a model from scratch on this dataset alone"
      ],
      "metadata": {
        "id": "8LuPB2W9gSVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "设计思路：\n",
        "\n",
        "2 层卷积 + 池化，适合小数据集，计算量低，防止过拟合。\n",
        "ReLU 作为默认激活函数，提高非线性表达能力。"
      ],
      "metadata": {
        "id": "FYO1elAWi2nV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# 构建 Simple CNN 模型\n",
        "def simple_cnn(input_shape=(32, 32, 3), num_classes=10):\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# 初始化模型\n",
        "model = simple_cnn()\n",
        "\n",
        "# 编译模型\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 训练模型\n",
        "history = model.fit(x_train_sub, y_train_sub,\n",
        "                    epochs=10,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(x_val_sub, y_val_sub))"
      ],
      "metadata": {
        "id": "YwOBPUe9epuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 评估模型\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"最终测试集准确率: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "GRX0vSiIn2oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "设计思路：\n",
        "\n",
        "4 层卷积 + 池化，增加特征提取能力。\n",
        "批归一化（Batch Normalization），加快训练并稳定收敛。\n",
        "Dropout（随机丢弃），防止过拟合。"
      ],
      "metadata": {
        "id": "BVAsHSiOizuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# 构建 Deep CNN 模型\n",
        "def deep_cnn(input_shape=(32, 32, 3), num_classes=10):\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.BatchNormalization(),\n",
        "\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.BatchNormalization(),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dropout(0.5),  # 防止过拟合\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# 初始化模型\n",
        "model = deep_cnn()\n",
        "\n",
        "# 编译模型\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 训练模型\n",
        "history = model.fit(x_train_sub, y_train_sub,\n",
        "                    epochs=20,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(x_val_sub, y_val_sub))\n",
        "\n",
        "# 评估模型\n",
        "test_loss, test_acc = model.evaluate(x_test_sub, y_test_sub)\n",
        "print(f\"最终测试集准确率: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "SWyLKkc0iw1D",
        "outputId": "f15e34d4-05e1-4b4a-8542-41b765aaa2f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 358ms/step - accuracy: 0.2395 - loss: 2.5642 - val_accuracy: 0.1120 - val_loss: 2.5036\n",
            "Epoch 2/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 356ms/step - accuracy: 0.3972 - loss: 1.7042 - val_accuracy: 0.1480 - val_loss: 3.4426\n",
            "Epoch 3/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 354ms/step - accuracy: 0.4732 - loss: 1.4641 - val_accuracy: 0.0890 - val_loss: 6.2937\n",
            "Epoch 4/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 336ms/step - accuracy: 0.5540 - loss: 1.2266 - val_accuracy: 0.0890 - val_loss: 6.7948\n",
            "Epoch 5/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 357ms/step - accuracy: 0.6707 - loss: 0.9623 - val_accuracy: 0.0890 - val_loss: 7.6902\n",
            "Epoch 6/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 340ms/step - accuracy: 0.7220 - loss: 0.7959 - val_accuracy: 0.1210 - val_loss: 4.6952\n",
            "Epoch 7/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 349ms/step - accuracy: 0.7934 - loss: 0.6045 - val_accuracy: 0.3060 - val_loss: 2.7190\n",
            "Epoch 8/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 353ms/step - accuracy: 0.8319 - loss: 0.4968 - val_accuracy: 0.4510 - val_loss: 1.9238\n",
            "Epoch 9/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 380ms/step - accuracy: 0.8592 - loss: 0.3844 - val_accuracy: 0.5280 - val_loss: 1.5938\n",
            "Epoch 10/20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "设计思路：\n",
        "\n",
        "引入残差连接（skip connection），防止梯度消失。\n",
        "适合较深的网络，提高训练稳定性。"
      ],
      "metadata": {
        "id": "H-mBX2Jwi8eF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, filters):\n",
        "    shortcut = x  # 直接连接\n",
        "\n",
        "    x = layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "\n",
        "    x = layers.Add()([x, shortcut])  # 残差连接\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def resnet_cnn(input_shape=(32, 32, 3), num_classes=10):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    x = residual_block(x, 32)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = residual_block(x, 64)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = layers.Flatten()\n",
        "    x = layers.Dense(256, activation='relu')\n",
        "    x = layers.Dropout(0.5)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "SzIctKrpi6SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inception_module(x, filters):\n",
        "    conv1x1 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "    conv3x3 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
        "    conv3x3 = layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(conv3x3)\n",
        "\n",
        "    conv5x5 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
        "    conv5x5 = layers.Conv2D(filters, (5, 5), padding='same', activation='relu')(conv5x5)\n",
        "\n",
        "    pooled = layers.MaxPooling2D((3, 3), strides=1, padding='same')(x)\n",
        "    pooled = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(pooled)\n",
        "\n",
        "    output = layers.concatenate([conv1x1, conv3x3, conv5x5, pooled], axis=-1)\n",
        "    return output\n",
        "\n",
        "def inception_cnn(input_shape=(32, 32, 3), num_classes=10):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    x = inception_module(inputs, 32)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = inception_module(x, 64)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = layers.Flatten()\n",
        "    x = layers.Dense(256, activation='relu')\n",
        "    x = layers.Dropout(0.5)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "FJ-JBj8PjBKZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.Training Strategy-pre-train a model on another dataset called CIFAR100 and fine-tune it on CIFAR10."
      ],
      "metadata": {
        "id": "VOASnEQNj3wN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UkGdQDVXj7iW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "da3f2328c5444c2a931e21e0c8570d48",
    "kernelspec": {
      "display_name": "py38_data",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6 (default, Sep 26 2022, 11:37:49) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
    },
    "orig_nbformat": 2,
    "vscode": {
      "interpreter": {
        "hash": "25f9a3951446179f6c2016b22a60b44495fe90f43bda7f3caedfe2c1a9cd31f9"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}